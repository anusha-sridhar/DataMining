nclust=3
rect.hclust(h,k=nclust)
#jpeg(filename = "./plots/Task_2.7_threecuts.jpeg")
groups3<-cutree(h, k=nclust)
#Cut the dendogram into 4
nclust=4
rect.hclust(h,k=nclust)
#jpeg(filename = "./plots/Task_2.7_fourcuts.jpeg")
groups4<-cutree(h, k=nclust)
#Cut the dendogram into 5
nclust=5
rect.hclust(hc,k=nclust)
#jpeg(filename = "./plots/Task_2.7_fivecuts.jpeg")
groups5<-cutree(h, k=nclust)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
table(groups2,groups3,groups4,groups5)
#Apply hierarchical clustering to the data using the hclust function with default parameters
n=nrow(breastcancerdata2)
idx<-sample(1:n, 40)
breastcancerdata2sample <- breastcancerdata2[idx,]
h <- hclust(dist(breastcancerdata2sample))
jpeg(filename = "./plots/Task_2.7_cutsnone.jpeg", width= 1500, height=1300)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
#dev.off()
#Cut the dendogram into 2
nclust=2
rect.hclust(h, k=nclust)
#jpeg(filename = "./plots/Task_2.7_twocuts.jpeg")
groups2<-cutree(h, k=nclust)
dev.off()
jpeg(filename = "./plots/Task_2.7_twocuts.jpeg")
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=2
rect.hclust(h, k=nclust)
groups2<-cutree(h, k=nclust)
dev.off()
#Apply hierarchical clustering to the data using the hclust function with default parameters
n=nrow(breastcancerdata2)
idx<-sample(1:n, 40)
breastcancerdata2sample <- breastcancerdata2[idx,]
h <- hclust(dist(breastcancerdata2sample))
jpeg(filename = "./plots/Task_2.7_cutsnone.jpeg", width= 1500, height=1300)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
dev.off()
jpeg(filename = "./plots/Task_2.7_twocuts.jpeg")
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=2
rect.hclust(h, k=nclust)
groups2<-cutree(h, k=nclust)
dev.off()
#plot by default
#save plot obtained in task 2.5, k=3
jpeg(filename = "./plots/Task_2.5_kequals3.jpeg")
plot(breastcancerdata2[c("Clump.Thickness","Uniformity.of.Cell.Size")],col=km3$cluster)
dev.off()
#kmeans cluster the data, k=4
km4 = kmeans(breastcancerdata2,4)
#plot by default
#save plot obtained in task 2.5, k=4
jpeg(filename = "./plots/Task_2.5_kequals4.jpeg")
plot(breastcancerdata2[c("Clump.Thickness","Uniformity.of.Cell.Size")],col=km4$cluster)
dev.off()
#kmeans cluster the data, k=5
km5 = kmeans(breastcancerdata2,5)
#plot by default
#save plot obtained in task 2.5, k=5
jpeg(filename = "./plots/Task_2.5_kequals5.jpeg")
plot(breastcancerdata2[c("Clump.Thickness","Uniformity.of.Cell.Size")],col=km5$cluster)
dev.off()
#sum of squares of each cluster
km$betweenss
km3$betweenss
km4$betweenss
#Apply hierarchical clustering to the data using the hclust function with default parameters
n=nrow(breastcancerdata2)
idx<-sample(1:n, 40)
breastcancerdata2sample <- breastcancerdata2[idx,]
h <- hclust(dist(breastcancerdata2sample))
jpeg(filename = "./plots/Task_2.7_cutsnone.jpeg", width= 1500, height= 1300)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
dev.off()
#Cut the dendogram into 2 clusters
jpeg(filename = "./plots/Task_2.7_2cuts.jpeg")
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=2
rect.hclust(h,k=nclust)
groups2<-cutree(h, k=nclust)
dev.off()
#Cut the dendogram into 3 clusters
jpeg(filename = "./plots/Task_2.7_3cuts.jpeg")
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=3
rect.hclust(h,k=nclust)
groups3<-cutree(h, k=nclust)
dev.off()
#Cut the dendogram into 4 clusters
jpeg(filename = "./plots/Task_2.7_4cuts.jpeg")
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=4
rect.hclust(h,k=nclust)
groups4<-cutree(h, k=nclust)
dev.off()
#Cut the dendogram into 5
jpeg(filename = "./plots/Task_2.7_5cuts.jpeg")
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=5
rect.hclust(h,k=nclust)
groups5<-cutree(h, k=nclust)
dev.off()
#Apply hierarchical clustering to the data using the hclust function with default parameters
n=nrow(breastcancerdata2)
idx<-sample(1:n, 40)
breastcancerdata2sample <- breastcancerdata2[idx,]
h <- hclust(dist(breastcancerdata2sample))
jpeg(filename = "./plots/Task_2.7_cutsnone.jpeg", width= 1500, height= 1300)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
dev.off()
#Cut the dendogram into 2 clusters
jpeg(filename = "./plots/Task_2.7_2cuts.jpeg", width= 1500, height= 1300)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=2
rect.hclust(h,k=nclust)
groups2<-cutree(h, k=nclust)
dev.off()
#Cut the dendogram into 3 clusters
jpeg(filename = "./plots/Task_2.7_3cuts.jpeg", width= 1500, height= 1300)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=3
rect.hclust(h,k=nclust)
groups3<-cutree(h, k=nclust)
dev.off()
#Cut the dendogram into 4 clusters
jpeg(filename = "./plots/Task_2.7_4cuts.jpeg", width= 1500, height= 1300)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=4
rect.hclust(h,k=nclust)
groups4<-cutree(h, k=nclust)
dev.off()
#Cut the dendogram into 5
jpeg(filename = "./plots/Task_2.7_5cuts.jpeg", width= 1500, height= 1300)
plot(h,hang=-1,labels = breastcancerdata1$Class[idx])
nclust=5
rect.hclust(h,k=nclust)
groups5<-cutree(h, k=nclust)
dev.off()
#single
hs <- hclust(dist(breastcancerdata2sample), method= "single")
jpeg(filename = "./plots/Task_2.7_single.jpeg", width= 1500, height= 1300)
plot(hs,hang=-1,labels = breastcancerdata1$Class[idx])
dev.off()
#complete
hc <- hclust(dist(breastcancerdata2sample), method="complete")
jpeg(filename = "./plots/Task_2.7_complete.jpeg", width= 1500, height= 1300)
plot(hc,hang=-1,labels = breastcancerdata1$Class[idx])
dev.off()
#average
ha <- hclust(dist(breastcancerdata2sample), method="average")
jpeg(filename = "./plots/Task_2.7_average.jpeg", width= 1500, height= 1300)
plot(ha,hang=-1,labels = breastcancerdata1$Class[idx])
dev.off()
breastcancerdata3
breastcancerdata3<-breastcancerdata1
breastcancerdata3
names(breastcancerdata3)
str(breastcancerdata3)
training_data
eastcancerdata1
breastcancerdata3<-breastcancerdata1
#setting seed
set.seed(6125)
#Divide the dataset into “training” and “test” subsets randomly (70% and 30% respectively)
m=nrow(breastcancerdata3)
training_precentage=0.7
test_percentage=0.3
#Sample random index
ind <- sample(2, m, replace = TRUE, prob = c(training_precentage, test_percentage))
#Set training and test data
training_data= breastcancerdata3[ind == 1, ]
test_data= breastcancerdata3[ind == 2, ]
training_data
test_data
breastcancerdata3
training_data
test_data
#Divide features and labels
training_features<-training_data[,1:4]
training_labels<-training_data[,5]
training_features
#Divide features and labels
training_features<-training_data[,1:9]
training_labels<-training_data[,10]
training_features
training_labels
#Specify target class and predictors
myFormula<-Class ~ Clump.Thickness + Uniformity.of.Cell.Size + Uniformity.of.Cell.Shape + Marginal.Adhesion + Single.Epithelial.Cell.Size + Bare.Nuclei + Bland.Chromatin + Normal.Nucleoli + Mitoses
#generate classification tree
bcd_ctree <- ctree(myFormula, data = training_data)
#install and import "party" library
install.packages("party")
library(party)
#Specify target class and predictors
myFormula<-Class ~ Clump.Thickness + Uniformity.of.Cell.Size + Uniformity.of.Cell.Shape + Marginal.Adhesion + Single.Epithelial.Cell.Size + Bare.Nuclei + Bland.Chromatin + Normal.Nucleoli + Mitoses
#generate classification tree
bcd_ctree <- ctree(myFormula, data = training_data)
#generate classification tree
bcd_ctree <- ctree(myFormula, data = training_data)
#Visualize the tree
plot(bcw_ctree)
#generate classification tree
bcd_ctree <- ctree(myFormula, data = training_data)
#Visualize the tree
plot(bcd_ctree)
plot(bcd_ctree, type="simple")
#Predict test labels
ctree_pred <- predict(bcw_ctree, newdata = test_features)
#Predict test labels
ctree_pred <- predict(bcd_ctree, newdata = test_features)
test_features<-test_data[,1:9]
test_labels<-test_data[,10]
#Predict test labels
ctree_pred <- predict(bcd_ctree, newdata = test_features)
#Visualize the tree
plot(bcd_ctree)
#Predict class labels
ctree_pred <- predict(bcd_ctree, newdata = test_features)
#Create confusion matrix
cm=as.matrix(table(Actual=test_labels, Predicted=ctree_pred))
n=sum(cm) #no of instances
nc=nrow(cm) #no of classes
diag=diag(cm) #no of correctly classified instances per class
rowsums=apply(cm, 1, sum) #no of instances per class
colsums=apply(cm, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy=sum(diag)/n
precision=diag/colsums
recall=diag/rowsums
f1=2*precision*recall/(precision+recall)
results<-data.frame(precison,recall,f1)
precision=diag/colsums
recall=diag/rowsums
f1=2*precision*recall/(precision+recall)
results<-data.frame(precison,recall,f1)
results<-data.frame(precision,recall,f1)
accuracy
results
cm
?ctree
#task3.3
bcd_ctree_modified<- ctree(myFormula, data = training_data, teststat="max", stump=FALSE, maxdepth=0, remove_weights=FALSE)
bcd_ctree_modified<- ctree(myFormula, data = training_data, controls = ctree_control(teststat = c("quad", "max"),
testtype = c("Bonferroni", "MonteCarlo",
"Univariate", "Teststatistic"),
mincriterion = 0.95, minsplit = 20, minbucket = 7,
stump = FALSE, nresample = 9999, maxsurrogate = 0,
mtry = 0, savesplitstats = TRUE, maxdepth = 0, remove_weights = FALSE))
bcd_ctree_modified
plot(bcd_ctree_modified)
plot(bcd_ctree)
#install and import "class" library
installed.packages("class")
library(class)
#Classifying using K-NN
knn_pred<-knn(training_features, test = test_features, cl=training_labels, k=3)
#Create confusion matrix
cm=as.matrix(table(Actual=test_labels, Predicted=ctree_pred))
n=sum(cm) #no of instances
nc=nrow(cm) #no of classes
diag=diag(cm) #no of correctly classified instances per class
rowsums=apply(cm, 1, sum) #no of instances per class
colsums=apply(cm, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy=sum(diag)/n
precision=diag/colsums
recall=diag/rowsums
f1=2*precision*recall/(precision+recall)
results<-data.frame(precision,recall,f1)
accuracy
results
cm
#Classifying using K-NN
knn_pred<-knn(training_features, test = test_features, cl=training_labels, k=1)
#Create confusion matrix
cm=as.matrix(table(Actual=test_labels, Predicted=ctree_pred))
n=sum(cm) #no of instances
nc=nrow(cm) #no of classes
diag=diag(cm) #no of correctly classified instances per class
rowsums=apply(cm, 1, sum) #no of instances per class
colsums=apply(cm, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy=sum(diag)/n
precision=diag/colsums
recall=diag/rowsums
f1=2*precision*recall/(precision+recall)
results<-data.frame(precision,recall,f1)
accuracy
results
cm
#Classifying using K-NN
knn_pred<-knn(training_features, test = test_features, cl=training_labels, k=1)
#Create confusion matrix
cm1=as.matrix(table(Actual=test_labels, Predicted=knn_pred))
n=sum(cm1) #no of instances
nc=nrow(cm1) #no of classes
diag=diag(cm1) #no of correctly classified instances per class
rowsums=apply(cm1, 1, sum) #no of instances per class
colsums=apply(cm1, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy1=sum(diag)/n
precision1=diag/colsums
recall1=diag/rowsums
f1_kequals1=2*precision*recall/(precision+recall)
results<-data.frame(precision,recall,f1)
accuracy
results
cm
f1_kequals1=2*precision1*recall1/(precision1+recall1)
results<-data.frame(precision1,recall1,f1)
accuracy
results
cm
accuracy1
results1
results
cm1
results1<-data.frame(precision1,recall1,f1_kequals1)
accuracy1
results1
cm1
#Classifying using K-NN when k=2
knn_pred2<-knn(training_features, test = test_features, cl=training_labels, k=2)
#Create confusion matrix
cm2=as.matrix(table(Actual=test_labels, Predicted=knn_pred2))
n2=sum(cm2) #no of instances
nc2=nrow(cm2) #no of classes
diag2=diag(cm2) #no of correctly classified instances per class
rowsums2=apply(cm2, 1, sum) #no of instances per class
colsums2=apply(cm2, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy2=sum(diag2)/n1
precision2=diag2/colsums2
#compute accuracy, precision, recall and f1
accuracy2=sum(diag2)/n2
precision2=diag2/colsums2
recall2=diag2/rowsums2
f1_kequals2=2*precision2*recall2/(precision2+recall2)
results2<-data.frame(precision2,recall2,f1_kequals2)
accuracy2
results2
cm2
#Classifying using K-NN when k=1
knn_pred<-knn(training_features, test = test_features, cl=training_labels, k=1)
#Create confusion matrix
cm1=as.matrix(table(Actual=test_labels, Predicted=knn_pred))
n1=sum(cm1) #no of instances
nc1=nrow(cm1) #no of classes
diag1=diag(cm1) #no of correctly classified instances per class
rowsums1=apply(cm1, 1, sum) #no of instances per class
colsums1=apply(cm1, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy1=sum(diag1)/n1
precision1=diag1/colsums1
recall1=diag1/rowsums1
f1_kequals1=2*precision1*recall1/(precision1+recall1)
results1<-data.frame(precision1,recall1,f1_kequals1)
accuracy1
results1
cm1
#Classifying using K-NN when k=2
knn_pred2<-knn(training_features, test = test_features, cl=training_labels, k=2)
#Create confusion matrix
cm2=as.matrix(table(Actual=test_labels, Predicted=knn_pred2))
n2=sum(cm2) #no of instances
nc2=nrow(cm2) #no of classes
diag2=diag(cm2) #no of correctly classified instances per class
rowsums2=apply(cm2, 1, sum) #no of instances per class
colsums2=apply(cm2, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy2=sum(diag2)/n2
precision2=diag2/colsums2
recall2=diag2/rowsums2
f1_kequals2=2*precision2*recall2/(precision2+recall2)
results2<-data.frame(precision2,recall2,f1_kequals2)
accuracy2
results2
cm2
knn_pred3<-knn(training_features, test = test_features, cl=training_labels, k=3)
#Create confusion matrix
cm3=as.matrix(table(Actual=test_labels, Predicted=knn_pred3))
n3 = sum(cm3) #no of instances
nc3 = nrow(cm3) #no of classes
diag3 = diag(cm3) #no of correctly classified instances per class
rowsums3 = apply(cm3, 1, sum) #no of instances per class
colsums3 = apply(cm3, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy3 = sum(diag3)/n3
precision3 = diag3/colsums3
recall3=diag3 / rowsums3
f1_kequals3 = 2 * precision3 * recall3 / (precision3 + recall3)
results3 <- data.frame(precision3, recall3, f1_kequals3)
accuracy3
results3
cm3
knn_pred4<-knn(training_features, test = test_features, cl=training_labels, k=4)
#Create confusion matrix
cm4=as.matrix(table(Actual=test_labels, Predicted=knn_pred4))
n4=sum(cm4) #no of instances
nc4=nrow(cm4) #no of classes
diag4=diag(cm4) #no of correctly classified instances per class
rowsums4=apply(cm4, 1, sum) #no of instances per class
colsums4=apply(cm4, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy4 = sum(diag4) / n4
precision4 = diag4 / colsums4
recall4 = diag4 / rowsums4
f1_kequals4 = 2*precision4*recall4 / (precision4+recall4)
results4 <- data.frame(precision4,recall4,f1_kequals4)
accuracy4
results4
cm4
knn_pred5<-knn(training_features, test = test_features, cl=training_labels, k=5)
#Create confusion matrix
cm5=as.matrix(table(Actual=test_labels, Predicted=knn_pred5))
n5=sum(cm5) #no of instances
nc5=nrow(cm5) #no of classes
diag5=diag(cm5) #no of correctly classified instances per class
rowsums5=apply(cm5, 1, sum) #no of instances per class
colsums5=apply(cm5, 2, sum) #no of predictions per class
#compute accuracy, precision, recall and f1
accuracy5 = sum(diag5) / n5
precision5 = diag5 / colsums5
recall5 = diag5 / rowsums5
f1_kequals5 = 2*precision5*recall5 / (precision5+recall5)
results5 <- data.frame(precision5,recall5,f1_kequals5)
accuracy5
results5
cm5
accuracy1
results1
cm1
accuracy2
results2
cm2
accuracy3
results3
cm3
accuracy4
results4
cm4
accuracy5
results5
cm5
str(breastcancerdata)
?str
#Visualize the tree
jpeg(filename = "./plots/Task_3.2.jpeg")
plot(bcd_ctree)
dev.off()
#Visualize the tree
jpeg(filename = "./plots/Task_3.2.jpeg" width=1500, height=1300)
plot(bcd_ctree)
#Visualize the tree
jpeg(filename = "./plots/Task_3.2.jpeg", width=1500, height=1300)
plot(bcd_ctree)
dev.off()
jpeg(filename = "./plots/Task_3.3.jpeg", width=1500, height=1300)
plot(bcd_ctree_modified)
dev.off()
bcd_ctree_modified<- ctree(myFormula, data = training_data, controls = ctree_control(teststat = c("quad", "max"),
testtype = c("Bonferroni", "MonteCarlo",
"Univariate", "Teststatistic"),
mincriterion = 0.5, minsplit = 10, minbucket = 4,
stump = FALSE, nresample = 9999, maxsurrogate = 0,                                                                                     mtry = 0, savesplitstats = TRUE, maxdepth = 0, remove_weights = FALSE))
jpeg(filename = "./plots/Task_3.3.jpeg", width=1500, height=1300)
plot(bcd_ctree_modified)
dev.off()
#sum of squares of each cluster
km$tot.withinss
km3$tot.withinss
km4$tot.withinss
km5$tot.withinss
#Printing data for comparison
accuracy1
results1
cm1
accuracy2
results2
cm2
accuracy3
results3
cm3
accuracy4
results4
cm4
accuracy5
results5
cm5
#Printing data for comparison
accuracy1
accuracy2
accuracy3
accuracy4
accuracy5
results1
results2
results3
results4
results5
cm1
cm2
cm3
cm4
cm5
